{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO5C9QYfXTw7E84DQTzukma",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SatishAwal/Machine-Learning-Foundations-Midterm-1/blob/main/FinalProjectML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Online Food Order Prediction Model\n",
        "## Problem Definition\n",
        "I'll design the basic prediction model to determine whether a customer is likely to order food online based on their demographic characteristics. The target variable is \"Output\"(Yes/No), making this a binary classification problem."
      ],
      "metadata": {
        "id": "yho18IMXd4-J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dataset Selection\n",
        "The dataset contains 388 records with 13 features including:\n",
        "\n",
        "* Demographic: Age, Gender, Marital Status, Occupation, Monthly Income, Education, Family Size\n",
        "\n",
        "* Geographic: Latitude, Longitude, Pin Code\n",
        "\n",
        "* Behavioral: Feedback (Positive/Negative)\n",
        "\n",
        "* Target: Output (Yes/No for online food ordering)\n"
      ],
      "metadata": {
        "id": "B-cdjpQsB0DE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "BTwCS7kyCbBH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(\"/content/onlinefoods.csv\")\n",
        "\n",
        "print(f\"Number of records and features are: {df.shape}\")\n",
        "\n",
        "# Data cleaning\n",
        "df.dropna(inplace=True)  # Remove any missing values\n",
        "df.drop_duplicates(inplace=True)  # Remove duplicates\n",
        "\n",
        "# Strip whitespace from 'Feedback' column\n",
        "df['Feedback'] = df['Feedback'].str.strip()\n",
        "# Strip \"Rs.\" from 'Monthly Income'\n",
        "df['Monthly Income'] = df['Monthly Income'].str.replace('Rs.', '', regex=False).str.strip()\n",
        "\n",
        "\n",
        "\n",
        "# Encode categorical variables\n",
        "label_encoders = {}\n",
        "categorical_cols = ['Gender', 'Marital Status', 'Occupation', 'Monthly Income',\n",
        "                   'Educational Qualifications', 'Feedback']\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    # Fit on the entire column to include all possible labels\n",
        "    le.fit(df[col])\n",
        "    df[col] = le.transform(df[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "# Encode target variable\n",
        "df['Output'] = df['Output'].map({'Yes': 1, 'No': 0})\n",
        "\n",
        "# Feature selection\n",
        "X = df.drop(['Output', 'latitude', 'longitude', 'Pin code', 'Unnamed: 12'], axis=1)\n",
        "y = df['Output']\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Scale numerical features\n",
        "scaler = StandardScaler()\n",
        "X_train[['Age', 'Family size']] = scaler.fit_transform(X_train[['Age', 'Family size']])\n",
        "X_test[['Age', 'Family size']] = scaler.transform(X_test[['Age', 'Family size']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7F1OrwisxqBf",
        "outputId": "64c4c0d8-d501-4dae-f482-dc9867e4c662"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of records and features are: (388, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Implementation\n",
        "\n",
        "I'll have implemented two models for comparison:\n",
        "* Logistic Regression\n",
        "* Decision Tree Classifier"
      ],
      "metadata": {
        "id": "IR5JeriOcnNP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 1: Logistic Regression\n",
        "log_reg = LogisticRegression(max_iter=1000)\n",
        "log_reg.fit(X_train, y_train)\n",
        "y_pred_log = log_reg.predict(X_test)\n",
        "\n",
        "# Model 2: Decision Tree\n",
        "dtree = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
        "dtree.fit(X_train, y_train)\n",
        "y_pred_dt = dtree.predict(X_test)"
      ],
      "metadata": {
        "id": "GMh-UtwwcrlD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "0P_huiBUcwho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation metrics\n",
        "print(\"Logistic Regression Performance:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_log):.2f}\")\n",
        "print(classification_report(y_test, y_pred_log))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred_log))\n",
        "\n",
        "print(\"\\nDecision Tree Performance:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_dt):.2f}\")\n",
        "print(classification_report(y_test, y_pred_dt))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred_dt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwehXhvdcytU",
        "outputId": "ce386d2a-7f86-4941-c11e-4c130bedf204"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Performance:\n",
            "Accuracy: 0.80\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.38      0.48        21\n",
            "           1       0.82      0.94      0.88        65\n",
            "\n",
            "    accuracy                           0.80        86\n",
            "   macro avg       0.75      0.66      0.68        86\n",
            "weighted avg       0.79      0.80      0.78        86\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 8 13]\n",
            " [ 4 61]]\n",
            "\n",
            "Decision Tree Performance:\n",
            "Accuracy: 0.79\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.43      0.50        21\n",
            "           1       0.83      0.91      0.87        65\n",
            "\n",
            "    accuracy                           0.79        86\n",
            "   macro avg       0.72      0.67      0.68        86\n",
            "weighted avg       0.77      0.79      0.78        86\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 9 12]\n",
            " [ 6 59]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparison and Justification\n",
        "Performance: The Logistic Regression  slightly outperforms  Decision Tree with 80% vs 79% accuracy.\n",
        "\n",
        "Interpretability:\n",
        "\n",
        "*   Logistic Regression provides coefficients showing feature importance\n",
        "\n",
        "*   Decision Tree offers visual rules for classification\n",
        "\n",
        "Feature Importance (from Decision Tree):\n",
        "\n",
        "*   Monthly Income is the most important predictor\n",
        "*   Occupation and Education level are also significant\n",
        "*   Geographic features (latitude/longitude) were less important\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mHC6aE_nde08"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sample Input to check the Model"
      ],
      "metadata": {
        "id": "3Tl4fMwsd0ct"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_online_food_use(user_input, label_encoders, scaler, log_reg, dtree):\n",
        "    import pandas as pd\n",
        "\n",
        "    # Convert input dictionary to DataFrame\n",
        "    sample = pd.DataFrame([user_input])\n",
        "\n",
        "    # Encode categorical variables\n",
        "    for col in ['Gender', 'Marital Status', 'Occupation', 'Monthly Income',\n",
        "                'Educational Qualifications', 'Feedback']:\n",
        "        sample[col] = label_encoders[col].transform(sample[col])\n",
        "\n",
        "    # Scale numerical features\n",
        "    sample[['Age', 'Family size']] = scaler.transform(sample[['Age', 'Family size']])\n",
        "\n",
        "    # Predictions\n",
        "    log_pred = log_reg.predict(sample)[0]\n",
        "    tree_pred = dtree.predict(sample)[0]\n",
        "\n",
        "    print(\"Predictions for Sample User:\")\n",
        "    print(f\"Logistic Regression: {'Yes' if log_pred == 1 else 'No'}\")\n",
        "    print(f\"Decision Tree: {'Yes' if tree_pred == 1 else 'No'}\")\n"
      ],
      "metadata": {
        "id": "iC_1J5tMy7tw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a sample user\n",
        "user_1= {\n",
        "    'Age': 55,\n",
        "    'Gender': 'Male',\n",
        "    'Marital Status': 'Married',\n",
        "    'Occupation': 'Self Employeed',\n",
        "    'Monthly Income': 'Below 10000',\n",
        "    'Educational Qualifications': 'Graduate',\n",
        "    'Family size': 6,\n",
        "    'Feedback': 'Negative'\n",
        "}\n",
        "\n",
        "user_2={\n",
        "    'Age': 25,\n",
        "    'Gender': 'Male',\n",
        "    'Marital Status': 'Single',\n",
        "    'Occupation': 'Student',\n",
        "    'Monthly Income': 'Below 10000',\n",
        "    'Educational Qualifications': 'Graduate',\n",
        "    'Family size': 3,\n",
        "    'Feedback': 'Positive'\n",
        "}\n",
        "# Call the prediction function\n",
        "predict_online_food_use(user_1, label_encoders, scaler, log_reg, dtree\n",
        ")\n",
        "print(\"\\n\")\n",
        "predict_online_food_use(user_2, label_encoders, scaler, log_reg, dtree\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZKGXDQ41JSm",
        "outputId": "5d56c397-461e-4522-90a5-60f14283a968"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions for Sample User:\n",
            "Logistic Regression: No\n",
            "Decision Tree: No\n",
            "\n",
            "\n",
            "Predictions for Sample User:\n",
            "Logistic Regression: Yes\n",
            "Decision Tree: Yes\n"
          ]
        }
      ]
    }
  ]
}